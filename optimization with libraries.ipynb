{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img\n",
    "src=\"https://www.imt-atlantique.fr/sites/default/files/Images/Ecole/charte-graphique/IMT_Atlantique_logo_RVB_Baseline_400x272.jpg\"\n",
    "WIDTH=200 HEIGHT=200>\n",
    "\n",
    "<CENTER>\n",
    "</br>\n",
    "<p><font size=\"5\"> TAF MCE - 2019</span></p>\n",
    "<p><font size=\"4\">  UE Numerical Methods </font></p>\n",
    "<p></p>\n",
    "<p><font size=\"5\">  Notebook 05: JuliaOpt - Julia optimization libraries - statement</font></p>\n",
    "</p></br>\n",
    "</p>\n",
    "</CENTER>\n",
    "\n",
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#00B8DE\"> I - Symbolic computation for optimization with Sympy</span>\n",
    "\n",
    "Sympy is a Python library for symbolic computation that can be interfaced simply with Julia. It can be used when possible to get closed form solution of optimization problems. Inside Julia, additional Julia syntaxes can be used to work with Sympy.\n",
    "\n",
    "## Refs:\n",
    "\n",
    "> - https://www.sympy.org/ (sympy website)\n",
    "> - https://github.com/JuliaPy/SymPy.jl (SymPy Julia interface)\n",
    "> - http://mth229.github.io/symbolic.html (tuto)\n",
    "> - https://github.com/jverzani/SymPy.jl/blob/master/examples/tutorial.md (tuto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[2K\u001b[?25h[1mFetching:\u001b[22m\u001b[39m [========================================>]  100.0 %.0 %\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m SpecialFunctions → `~/.julia/packages/SpecialFunctions/ne2iw/deps/build.log`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"SymPy\")\n",
    "Pkg.build(\"SpecialFunctions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#00B8DE\"> a) - Example </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\[ \\left[ \\begin{array}{r}- \\frac{1}{4} - \\frac{\\sqrt{39} i}{4}\\\\- \\frac{1}{4} + \\frac{\\sqrt{39} i}{4}\\end{array} \\right] \\]"
      ],
      "text/plain": [
       "2-element Array{Sym,1}:\n",
       " -1/4 - sqrt(39)*I/4\n",
       " -1/4 + sqrt(39)*I/4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using SymPy\n",
    "#using LaTeXStrings\n",
    "\n",
    "@vars z\n",
    "solve((2z^2+z+5)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{equation*}4 z^{3} + 2 z + 6\\end{equation*}"
      ],
      "text/plain": [
       "   3          \n",
       "4⋅z  + 2⋅z + 6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff(z^4+z^2+6z,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, -1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = symbols(\"a\",positive=true)\n",
    "b = symbols(\"b\",negative=true)\n",
    "diff(abs(a)),diff(abs(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#00B8DE\"> b) - Constrained optimization: equality constraint </span>\n",
    "\n",
    "Using Sympy solve \n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{l}\n",
    "{\\text{opt}}_{x,y}\\; f(x,y) = xy \\\\\n",
    "{\\text {s.t.}}\\; h(x,y) = \\left(\\dfrac x a \\right)^2 + \\left(\\dfrac y b \\right)^2-1=0\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Tuple{Sym,Sym,Sym},1}:\n",
       " (-sqrt(2)*a/2, -sqrt(2)*b/2, -a*b/2)\n",
       " (-sqrt(2)*a/2, sqrt(2)*b/2, a*b/2)  \n",
       " (sqrt(2)*a/2, -sqrt(2)*b/2, a*b/2)  \n",
       " (sqrt(2)*a/2, sqrt(2)*b/2, -a*b/2)  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import SymPy\n",
    "# Parameters & functions\n",
    "@vars x y\n",
    "a,b    = symbols(\"a b\", positive=true)\n",
    "λ      = symbols(\"λ\",real=true)\n",
    "f(x,y) = x*y\n",
    "h(x,y) = x^2/a^2 + y^2/b^2 - 1\n",
    "# Solution\n",
    "L(x,y) = f(x,y) + λ * h(x,y)\n",
    "∇L(x,y) = [diff(L(x,y),x), diff(L(x,y),y),h(x,y)]\n",
    "solve(∇L(x,y),(x,y,λ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#00B8DE\"> c) - Constrained optimization: inequality constraint </span>\n",
    "\n",
    "Using Sympy solve \n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{l}\n",
    "{\\text{opt}}_{x,y}\\; f(x,y) = xy \\\\\n",
    "{\\text {s.t.}}\\; g_1(x,y) = (\\frac x a)^2 + (\\frac y b)^2\\leq 1;\\quad g_2(x,y) = -bx-ay+ab \\leq 0\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Array{NTuple{4,Sym},1}:\n",
       " (0, 0, 0, 0)                           \n",
       " (0, b, a*b/2, 1)                       \n",
       " (a/2, b/2, 0, 1/2)                     \n",
       " (a, 0, a*b/2, 1)                       \n",
       " (-sqrt(2)*a/2, -sqrt(2)*b/2, -a*b/2, 0)\n",
       " (-sqrt(2)*a/2, sqrt(2)*b/2, a*b/2, 0)  \n",
       " (sqrt(2)*a/2, -sqrt(2)*b/2, a*b/2, 0)  \n",
       " (sqrt(2)*a/2, sqrt(2)*b/2, -a*b/2, 0)  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import SymPy\n",
    "# Parameters & functions\n",
    "@vars x y\n",
    "a,b    = symbols(\"a b\", positive=true)\n",
    "λ1,λ2    = symbols(\"λ1 λ2\",real=true)\n",
    "f(x,y) = x*y\n",
    "g1(x,y) = x^2/a^2 + y^2/b^2 - 1\n",
    "g2(x,y) = -b*x -a*y +a*b\n",
    "# Solution\n",
    "L(x,y) = f(x,y) + λ1 * g1(x,y) + λ2 * g2(x,y)\n",
    "∇L(x,y) = [diff(L(x,y),x), diff(L(x,y),y), λ1*g1(x,y), λ2*g2(x,y)]\n",
    "solve(∇L(x,y),(x,y,λ1,λ2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#00B8DE\"> II - Using JuliaOpt</span>\n",
    "\n",
    "If high performance numerical optimization is searched for optimization, one can look at **JuliaOpt** (http://www.juliaopt.org/), an organization that brings together packages related to optimization. In particular it supplies\n",
    "\n",
    "> - Julia standalone packages such as **Optim.jl** or **Convex.jl**\n",
    "> - modeling languages\n",
    "> - external solver interfaces\n",
    "<!-- >![alt text](./optim_overview.png) -->\n",
    "\n",
    "#### *Note:* **MathProgBase** library is an API (Application Programming Interface) for mathematical optimization solvers that has been replaced recently by **MathOptInterface**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refs:\n",
    "\n",
    "> - https://www.juliaopt.org/ (JuliaOpt)\n",
    "> - http://www.juliaopt.org/packages/ (JuliaOpt packages list)\n",
    "> - https://github.com/JuliaOpt/Convex.jl (Convex)\n",
    "> - https://convexjl.readthedocs.io/en/latest/\n",
    "> - http://www.juliaopt.org/JuMP.jl/v0.19.0/ (JuMP)\n",
    "> - https://github.com/JuliaOpt/MathOptInterface.jl (MathOptInterface)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#00B8DE\"> a) Minimizing Rosenborck's function with Optim.jl</span>\n",
    "\n",
    "**Optim.jl**: a project to implement basic optimization algorithms in pure Julia for univariate and multivariate optimization.\n",
    "\n",
    "\n",
    "https://github.com/JuliaNLSolvers/Optim.jl\n",
    "\n",
    "Minimize Rosenbrock's $f({\\bf x})=\\sum_{i=1:n-1}[(1-{\\bf x}_i)^2+100(x_{i+1}-x_i^2)^2]$ with library **Optim.jl**\n",
    "using the conjugate gradient method. \n",
    "> - First let the algorithm compute the gradient by itself. Compare several optimization methods.\n",
    "> - Then, call the optimization function supplying the gradient function. \n",
    "> - Compare execution time\n",
    "\n",
    "Choose for instance $n=10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"Optim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rosenbrock (generic function with 1 method)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function rosenbrock(x)\n",
    "    \n",
    "    out = 0\n",
    "    \n",
    "    N = length(x)\n",
    "    \n",
    "    for i in 1:N-1\n",
    "            \n",
    "        out += (1.0 - x[i])^2 + 100.0 * (x[i+1] - x[i]^2)^2\n",
    "    end\n",
    "    \n",
    "    return out\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "∇_Ros! (generic function with 1 method)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function ∇_Ros!(∇,x)\n",
    "    \n",
    "    N = length(x)\n",
    "    \n",
    "    ∇[1] = -2.0 * (1.0 - x[1]) - 400.0 * (x[2] - x[1]^2) * x[1]\n",
    "    \n",
    "    for i in 2:N-1\n",
    "                \n",
    "        ∇[i] = -2.0 * (1.0 - x[i]) - 400.0 * (x[i+1] - x[i]^2) * x[i] + 200.0 * (x[i] - x[i-1]^2)\n",
    "        \n",
    "    end \n",
    "    \n",
    "    ∇[N] = 200.0 * (x[N] - x[N-1]^2)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rosenbrock10 (generic function with 1 method)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function rosenbrock10(x)\n",
    "    \n",
    "    N = 10\n",
    "    \n",
    "    out = 0\n",
    "    \n",
    "    for i in 1:N-1\n",
    "                    \n",
    "        out += (1.0 - x[i])^2 + 100.0 * (x[i+1] - x[i]^2)^2\n",
    "    end\n",
    "    \n",
    "    return out\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "∇_Ros10! (generic function with 1 method)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function ∇_Ros10!(∇,x)\n",
    "    \n",
    "    N = 10\n",
    "    \n",
    "    ∇[1] = -2.0 * (1.0 - x[1]) - 400.0 * (x[2] - x[1]^2) * x[1]\n",
    "    \n",
    "    for i in 2:N-1\n",
    "                \n",
    "        ∇[i] = -2.0 * (1.0 - x[i]) - 400.0 * (x[i+1] - x[i]^2) * x[i] + 200.0 * (x[i] - x[i-1]^2)\n",
    "        \n",
    "    end \n",
    "    \n",
    "    ∇[N] = 200.0 * (x[N] - x[N-1]^2)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{equation*}\\left(- x_{1} + 1.0\\right)^{2} + 100.0 \\left(- x_{1}^{2} + x_{2}\\right)^{2} + \\left(- x_{2} + 1.0\\right)^{2} + 100.0 \\left(- x_{2}^{2} + x_{3}\\right)^{2} + \\left(- x_{3} + 1.0\\right)^{2} + 100.0 \\left(- x_{3}^{2} + x_{4}\\right)^{2}\\end{equation*}"
      ],
      "text/plain": [
       "                                 2                                    2       \n",
       "           2         ⎛    2     ⎞               2         ⎛    2     ⎞        \n",
       "(-x₁ + 1.0)  + 100.0⋅⎝- x₁  + x₂⎠  + (-x₂ + 1.0)  + 100.0⋅⎝- x₂  + x₃⎠  + (-x₃\n",
       "\n",
       "                             2\n",
       "       2         ⎛    2     ⎞ \n",
       " + 1.0)  + 100.0⋅⎝- x₃  + x₄⎠ "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@vars x1 x2 x3 x4\n",
    "rosenbrock([x1,x2,x3,x4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjugate Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000863 seconds (4.59 k allocations: 167.547 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " * Status: success\n",
       "\n",
       " * Candidate solution\n",
       "    Minimizer: [1.00e+00, 1.00e+00, 1.00e+00,  ...]\n",
       "    Minimum:   1.812227e-16\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     Conjugate Gradient\n",
       "    Initial Point: [0.00e+00, 0.00e+00, 0.00e+00,  ...]\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = 2.09e-11 ≰ 0.0e+00\n",
       "    |x - x'|/|x'|          = 2.09e-11 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|         = 1.63e-18 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = 9.00e-03 ≰ 0.0e+00\n",
       "    |g(x)|                 = 7.52e-09 ≤ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   0  (vs limit Inf)\n",
       "    Iterations:    194\n",
       "    f(x) calls:    405\n",
       "    ∇f(x) calls:   212\n"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Optim\n",
    "N = 10\n",
    "\n",
    "@time result = optimize(rosenbrock, zeros(N), ConjugateGradient())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000299 seconds (4.26 k allocations: 153.063 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " * Status: success\n",
       "\n",
       " * Candidate solution\n",
       "    Minimizer: [1.00e+00, 1.00e+00, 1.00e+00,  ...]\n",
       "    Minimum:   2.369349e-17\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     Conjugate Gradient\n",
       "    Initial Point: [0.00e+00, 0.00e+00, 0.00e+00,  ...]\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = 1.92e-11 ≰ 0.0e+00\n",
       "    |x - x'|/|x'|          = 1.92e-11 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|         = 2.19e-19 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = 9.24e-03 ≰ 0.0e+00\n",
       "    |g(x)|                 = 4.47e-09 ≤ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   0  (vs limit Inf)\n",
       "    Iterations:    175\n",
       "    f(x) calls:    354\n",
       "    ∇f(x) calls:   180\n"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time optimize(rosenbrock, ∇_Ros!, zeros(N), ConjugateGradient())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000247 seconds (1.44 k allocations: 60.328 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " * Status: success\n",
       "\n",
       " * Candidate solution\n",
       "    Minimizer: [1.00e+00, 1.00e+00, 1.00e+00,  ...]\n",
       "    Minimum:   1.617061e-16\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     BFGS\n",
       "    Initial Point: [0.00e+00, 0.00e+00, 0.00e+00,  ...]\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = 4.66e-09 ≰ 0.0e+00\n",
       "    |x - x'|/|x'|          = 4.66e-09 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|         = 9.67e-17 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = 5.98e-01 ≰ 0.0e+00\n",
       "    |g(x)|                 = 5.52e-09 ≤ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   0  (vs limit Inf)\n",
       "    Iterations:    65\n",
       "    f(x) calls:    159\n",
       "    ∇f(x) calls:   159\n"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Optim\n",
    "\n",
    "@time result = optimize(rosenbrock10, zeros(N), BFGS())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000189 seconds (1.45 k allocations: 60.375 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " * Status: success\n",
       "\n",
       " * Candidate solution\n",
       "    Minimizer: [1.00e+00, 1.00e+00, 1.00e+00,  ...]\n",
       "    Minimum:   7.443667e-25\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     BFGS\n",
       "    Initial Point: [0.00e+00, 0.00e+00, 0.00e+00,  ...]\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = 4.59e-10 ≰ 0.0e+00\n",
       "    |x - x'|/|x'|          = 4.59e-10 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|         = 6.42e-19 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = 8.63e+05 ≰ 0.0e+00\n",
       "    |g(x)|                 = 1.95e-11 ≤ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   0  (vs limit Inf)\n",
       "    Iterations:    65\n",
       "    f(x) calls:    160\n",
       "    ∇f(x) calls:   160\n"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time optimize(rosenbrock10, ∇_Ros10!, zeros(N), BFGS())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.002580 seconds (21.55 k allocations: 825.047 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " * Status: failure (reached maximum number of iterations) (line search failed)\n",
       "\n",
       " * Candidate solution\n",
       "    Minimizer: [9.97e-01, 9.94e-01, 9.89e-01,  ...]\n",
       "    Minimum:   3.899416e-01\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     Gradient Descent\n",
       "    Initial Point: [0.00e+00, 0.00e+00, 0.00e+00,  ...]\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = 7.29e-04 ≰ 0.0e+00\n",
       "    |x - x'|/|x'|          = 7.31e-04 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|         = 1.19e-03 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = 3.06e-03 ≰ 0.0e+00\n",
       "    |g(x)|                 = 5.96e-01 ≰ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   0  (vs limit Inf)\n",
       "    Iterations:    1000\n",
       "    f(x) calls:    2502\n",
       "    ∇f(x) calls:   2502\n"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time result = optimize(rosenbrock10, zeros(N), GradientDescent())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.001804 seconds (21.55 k allocations: 824.984 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " * Status: failure (reached maximum number of iterations) (line search failed)\n",
       "\n",
       " * Candidate solution\n",
       "    Minimizer: [9.97e-01, 9.94e-01, 9.89e-01,  ...]\n",
       "    Minimum:   3.899416e-01\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     Gradient Descent\n",
       "    Initial Point: [0.00e+00, 0.00e+00, 0.00e+00,  ...]\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = 7.29e-04 ≰ 0.0e+00\n",
       "    |x - x'|/|x'|          = 7.31e-04 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|         = 1.19e-03 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = 3.06e-03 ≰ 0.0e+00\n",
       "    |g(x)|                 = 5.96e-01 ≰ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   0  (vs limit Inf)\n",
       "    Iterations:    1000\n",
       "    f(x) calls:    2502\n",
       "    ∇f(x) calls:   2502\n"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time optimize(rosenbrock10, ∇_Ros10!, zeros(N), GradientDescent())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the three methods used, we can see that when we supply the gradient the convergence is faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#00B8DE\"> b) Linear and quadratic problems with Convex.jl</span>\n",
    "\n",
    "**Convex.jl**: A Julia library for solving linear and convex problems via disciplined convex optimization (see the first slides of http://stanford.edu/~boyd/papers/pdf/dcp_talk.pdf for an introduction to the subject)\n",
    "\n",
    "<!-- \n",
    "Examples: https://nbviewer.jupyter.org/github/JuliaOpt/Convex.jl/blob/master/examples/basic_usage.ipynb\n",
    "\n",
    "https://convexjl.readthedocs.io/en/latest/quick_tutorial.html \n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "import Pkg\n",
    "Pkg.add(\"Convex\") \n",
    "Pkg.add(\"ECOS\") # a lightweight LQ (linear and quadratic) and conic solver "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#00B8DE\"> Examples: linear programming</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem status = Optimal\n",
      "[x, y, z]= [1.0, 1.0, 0.25]\n"
     ]
    }
   ],
   "source": [
    "using Convex\n",
    "using ECOS\n",
    "\n",
    "x = Variable()\n",
    "y = Variable()\n",
    "z = Variable()\n",
    "expr = x + y + z\n",
    "    problem = minimize(expr, x >= 1, y >= x, 4 * z >= y)\n",
    "solve!(problem, ECOSSolver(verbose=0))\n",
    "println(\"problem status = $(problem.status)\")\n",
    "println(\"[x, y, z]= $([round.(a.value; digits=2) for a in (x, y, z)])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem status = Optimal\n",
      "objective = 81.5\n",
      "x_opt = [1.5; 5.0; 10.0; 10.0]\n",
      "x[1] + x[4] - x[2] = [6.0]\n"
     ]
    }
   ],
   "source": [
    "using LinearAlgebra: Diagonal\n",
    "\n",
    "x = Variable(4)\n",
    "c = [1; 2; 3; 4]\n",
    "A = Diagonal(ones(4))\n",
    "b = [10; 10; 10; 10]\n",
    "p = Convex.maximize(dot(c, x)) # or c' * x\n",
    "p.constraints += A * x <= b\n",
    "p.constraints += [x >=0 ; x <= 10; x[2] <= 5; x[1] + x[4] - x[2] <= 6.5]\n",
    "Convex.solve!(p, ECOSSolver(verbose=0))\n",
    "\n",
    "println(\"problem status = $(p.status)\")\n",
    "println(\"objective = $(round(p.optval; digits=2))\")\n",
    "println(\"x_opt = $(round.(x.value; digits=2))\")\n",
    "println(\"x[1] + x[4] - x[2] = $(round.(evaluate(x[1] + x[4] - x[2])))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#00B8DE\"> Exercise: constrained minimum squared error</span>\n",
    "\n",
    "> - Write and test a function to solve \n",
    "$$\n",
    "\\min \\parallel{\\bf Ax}-{\\bf b}\\parallel\\; s.t.\\; {\\bf x}\\succeq 0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem status = Optimal\n",
      "objective = -0.0\n",
      "x_opt = [0.41; 0.42; 3.2; 4.38; 6.47]\n"
     ]
    }
   ],
   "source": [
    "function MSE(A,b)\n",
    "    # Minimize ||Ax - b||^2 subject to x >= 0\n",
    "    x = Variable(size(A)[2])\n",
    "    v = A * x - b\n",
    "    p = Convex.minimize(sumsquares(v))\n",
    "    p.constraints += [x>=0]\n",
    "    Convex.solve!(p, ECOSSolver(verbose=0))\n",
    "    \n",
    "    println(\"problem status = $(p.status)\")\n",
    "    println(\"objective = $(round(p.optval; digits=2))\")\n",
    "    println(\"x_opt = $(round.(x.value; digits=2))\")\n",
    "end\n",
    "    \n",
    "# Generate random problem data\n",
    "m = 3;  n = 5\n",
    "A = randn(m, n); b = randn(m, 1)\n",
    "MSE(A,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#00B8DE\"> c) Using JuMP.jl</span>\n",
    "\n",
    "We will look at **JuMP** modeling language and use it with several optimization solvers.\n",
    "\n",
    "**Notes** \n",
    "> - The API **MathProgBase** is being deprecated and replaced by **MathOptInterface**\n",
    "> - Some packages need installation of additional libraries, possibly as a super-user (see system administrator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m JuMP ─ v0.20.1\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      " \u001b[90m [4076af6c]\u001b[39m\u001b[92m + JuMP v0.20.1\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      " \u001b[90m [4076af6c]\u001b[39m\u001b[92m + JuMP v0.20.1\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"JuMP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "#Pkg.add(\"Cbc\")      # LQ (linear and quadratic) programming\n",
    "#Pkg.add(\"Clp\")      # LQ programming\n",
    "#Pkg.add(\"SCS\")      # popular for cone programming\n",
    "#Pkg.add(\"Pajarito\") # MICP (mixed integer constraint)\n",
    "Pkg.add(\"Ipopt\")    # Interior Point Optimizer \n",
    "#Pkg.add(\"NLopt\")    # nonlinear optimization\n",
    "#Pkg.add(\"GLPK\")     # GNU Linear Programming Kit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#00B8DE\"> Example 1: linear program</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max 5 x + 3 y\n",
      "Subject to\n",
      " x + 5 y ≤ 3.0\n",
      " x ≥ 0.0\n",
      " y ≥ 0.0\n",
      " x ≤ 2.0\n",
      " y ≤ 30.0\n",
      "\n",
      "Objective value: 10.6\n",
      "x = 2.0\n",
      "y = 0.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://github.com/JuliaOpt/JuMP.jl/blob/master/examples/basic.jl\n",
    "using JuMP, GLPK, Test\n",
    "\"\"\"\n",
    "example_basic([verbose = true])\n",
    "Formulate and solve a simple LP:\n",
    "    max 5x + 3y\n",
    "     st 1x + 5y <= 3\n",
    "         0 <= x <= 2\n",
    "         0 <= y <= 30\n",
    "If `verbose = true`, print the model and the solution.\n",
    "\"\"\"\n",
    "function example_basic(verbose=true)\n",
    "    model = Model(with_optimizer(GLPK.Optimizer))\n",
    "    @variable(model, 0 <= x <= 2)\n",
    "    @variable(model, 0 <= y <= 30)\n",
    "    @objective(model, Max, 5x + 3y)\n",
    "    @constraint(model, 1x + 5y <= 3.0)\n",
    "\n",
    "    #set_silent(model)\n",
    "    if verbose\n",
    "        print(model)\n",
    "    end\n",
    "\n",
    "    optimize!(model)\n",
    "    if verbose\n",
    "        println(\"\\nObjective value: $(objective_value(model))\")\n",
    "        println(\"x = $(value(x))\")\n",
    "        println(\"y = $(value(y))\")\n",
    "    end\n",
    "\n",
    "    @test objective_value(model) ≈ 10.6\n",
    "    @test value(x) ≈ 2\n",
    "    @test value(y) ≈ 0.2\n",
    "end\n",
    "\n",
    "verbose = true\n",
    "example_basic(verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x+5y=3, x=2, 5+μ+ν=0, 3+5μ=0 ⇒ x,y,μ,ν=2,0.2,-2/3,-13/3\n",
    "μ and ν are negative (maximization problem) and other multipliers set to 0, Khun&Tucker conditions are satisfied and problem is convex. Hence we got the true solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#00B8DE\"> Example 2: quadratic objective</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min x² + 2 x*y + y²\n",
      "Subject to\n",
      " x + y ≥ 1.0\n",
      " x ≥ 0.0\n",
      " y ≥ 0.0\n",
      " x ≤ 2.0\n",
      " y ≤ 30.0\n",
      "\n",
      "Objective value: 1.0\n",
      "x = 0.28\n",
      "y = 0.72\n"
     ]
    }
   ],
   "source": [
    "using JuMP\n",
    "using Ipopt\n",
    "\n",
    "function example_quadratic(verbose = true)\n",
    "    m = Model(with_optimizer(Ipopt.Optimizer,print_level=0))\n",
    "    @variable(m, 0 <= x <= 2 )\n",
    "    @variable(m, 0 <= y <= 30 )\n",
    "    @objective(m, Min, x*x+ 2x*y + y*y)\n",
    "    @constraint(m, x + y >= 1 )\n",
    " \n",
    "    if verbose\n",
    "        print(m)\n",
    "    end\n",
    "\n",
    "    set_silent(m)\n",
    "    optimize!(m)\n",
    "    if verbose\n",
    "        println(\"\\nObjective value: $(round(objective_value(m);digits=2))\")\n",
    "        println(\"x = $(round(value(x);digits=2))\")\n",
    "        println(\"y = $(round(value(y);digits=2))\")\n",
    "    end\n",
    "end\n",
    "\n",
    "example_quadratic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#00B8DE\"> Example 3: conic constraints</span>\n",
    "\n",
    "Let $x\\in\\mathbb{R}^{n+1}, A\\in\\mathbb{R}^{n\\times n}, b\\in\\mathbb{R}^{n}$. Solve \n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{l}\n",
    "\\min_{x} \\parallel x-u\\parallel \\\\\n",
    "{\\text {s.t.}}\\; \\parallel Ax_{1:n}-b\\parallel \\leq x_{n+1};\\;x\\geq 0\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min t\n",
      "Subject to\n",
      " [t, x[1] + 0.7578265483823386, x[2] - 1.6942749358728655, x[3] + 0.3647477869287509, x[4] + 0.8116409533402457] ∈ MathOptInterface.SecondOrderCone(5)\n",
      " [x[5], -1.6521932946195572 x[1] + 0.024564448652553663 x[2] - 1.2848319227679927 x[3] + 0.7012862533187282 x[4] - 0.04192602599590368, 0.35980972389649585 x[1] + 0.16138616997464175 x[2] + 2.209078607235978 x[3] + 1.5231578909391517 x[4] - 0.17021383104017934, 0.1536682840079363 x[1] - 0.5138685986002539 x[2] + 1.709832263155149 x[3] - 0.5035558348292005 x[4] + 0.005390792338667495, -1.6182771305345947 x[1] + 2.986915687340239 x[2] + 1.136839087446193 x[3] - 0.8846924643721332 x[4] - 0.9638425277646077] ∈ MathOptInterface.SecondOrderCone(5)\n",
      " x[1] ≥ 0.0\n",
      " x[2] ≥ 0.0\n",
      " x[3] ≥ 0.0\n",
      " x[4] ≥ 0.0\n",
      " x[5] ≥ 0.0\n",
      "\n",
      "Objective value: 1.17\n",
      "x = [0.0, 1.69, 0.0, 0.0]\n",
      "t = 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling JuMP [4076af6c-e467-56ae-b986-b466b2749572]\n",
      "└ @ Base loading.jl:1242\n",
      "WARNING: using JuMP.Constant in module Main conflicts with an existing identifier.\n"
     ]
    }
   ],
   "source": [
    "using JuMP, ECOS, LinearAlgebra\n",
    "\n",
    "function example_quadratic(n; verbose = true)\n",
    "    A = randn(n,n)\n",
    "    b = randn(n)\n",
    "    u = randn(n)\n",
    "\n",
    "    m = Model(with_optimizer(ECOS.Optimizer))\n",
    "    @variable(m, x[i=1:n+1]>=0)\n",
    "    ##########################\n",
    "    @variable(m, t)\n",
    "    @objective(m, Min, t)\n",
    "    @constraint(m, vcat(t, (x[1:n]-u)) in SecondOrderCone())\n",
    "    ##########################\n",
    "    # Know also works with\n",
    "    # @objective(m, Min, (x[1:n]-u)'*(x[1:n]-u))\n",
    "    u = vcat(x[n+1],(A*x[1:n]-b))\n",
    "    @constraint(m, u in SecondOrderCone())\n",
    "\n",
    "    print(m)\n",
    "\n",
    "    std = stdout # save original stdout stream\n",
    "    redirect_stdout()\n",
    "    JuMP.optimize!(m)\n",
    "    redirect_stdout(std) # restore stdout\n",
    "\n",
    "    println(\"\\nObjective value: $(round.(JuMP.objective_value(m);digits=2))\")\n",
    "    println(\"x = $(round.([JuMP.value(x[k]) for k=1:n];digits=2))\")\n",
    "    println(\"t = $(round.(JuMP.value(t);digits=2))\")\n",
    "end\n",
    "\n",
    "example_quadratic(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#00B8DE\"> Exercise 1: nonlinear optimization</span>\n",
    "\n",
    "Using **Ipopt** solver, solve\n",
    "\n",
    "$$\n",
    "\\max_{x,y} xy^2\\\\\n",
    "{\\text {s.t.}}\\; x^3+y^2= 1;\\;x\\geq 0;\\;y\\geq 0\n",
    "$$\n",
    "\n",
    "Compare the result obtained with the theoretical solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max x * y ^ 2.0\n",
      "Subject to\n",
      " x ≥ 0.0\n",
      " y ≥ 0.0\n",
      " (x ^ 3.0 + y ^ 2.0) - 1.0 = 0\n",
      "\n",
      "Objective value: 0.47\n",
      "x = 0.6299605253670073\n",
      "y = 0.8660254034964514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(x, y)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using JuMP, Ipopt\n",
    "\n",
    "function excercise_one(verbose = true)\n",
    "\n",
    "    m = Model(with_optimizer(Ipopt.Optimizer))\n",
    "    @variable(m, x>=0)\n",
    "    @variable(m, y>=0)\n",
    "    @NLobjective(m, Max, x*y^2)\n",
    "    @NLconstraint(m,x^3+y^2==1.0)\n",
    "\n",
    "    print(m)\n",
    "    \n",
    "    std = stdout # save original stdout stream\n",
    "    redirect_stdout()\n",
    "    optimize!(m)\n",
    "    redirect_stdout(std) # restore stdout\n",
    "    \n",
    "    println(\"\\nObjective value: $(round(objective_value(m);digits=2))\")\n",
    "    println(\"x = $(value(x))\")\n",
    "    println(\"y = $(value(y))\")\n",
    "    \n",
    "    return x,y\n",
    "    \n",
    "end\n",
    "\n",
    "x,y = excercise_one()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error evaluation: [εx,εy] = [4.1957082252963573e-10, -2.879871896510622e-10]"
     ]
    }
   ],
   "source": [
    "# s = print(\"\\U221B\")\n",
    "print(\"Error evaluation: [εx,εy] = \")\n",
    "print(\"[\", JuMP.value(x)-1/∛4,\", \", JuMP.value(y)-√3/2,\"]\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#00B8DE\"> Exercise 2: nonlinear optimization (SISEA Master, June 2016)</span>\n",
    "\n",
    "Using **Ipopt** solver, solve\n",
    "$$\n",
    "{\\text {solve}}\\; \\min_{x,y} x-y^2\\\\\n",
    "{\\text {s.t.}}\\; x^2+y^2\\leq 1\n",
    "$$\n",
    "\n",
    "Compare the result obtained with the theoretical solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min x - y ^ 2.0\n",
      "Subject to\n",
      " x ≥ 0.0\n",
      " y ≥ 0.0\n",
      " (x ^ 3.0 + y ^ 2.0) - 1.0 ≤ 0\n",
      "\n",
      "Objective value: -1.0\n",
      "x = 0.0\n",
      "y = 1.0000000037466314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(x, y)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using JuMP, Ipopt\n",
    "\n",
    "function excercise_two(verbose = true)\n",
    "\n",
    "    m = Model(with_optimizer(Ipopt.Optimizer))\n",
    "    @variable(m, x>=0)\n",
    "    @variable(m, y>=0)\n",
    "    @NLobjective(m, Min, x-y^2)\n",
    "    @NLconstraint(m,x^3+y^2<=1.0)\n",
    "\n",
    "    print(m)\n",
    "    \n",
    "    std = stdout # save original stdout stream\n",
    "    redirect_stdout()\n",
    "    optimize!(m)\n",
    "    redirect_stdout(std) # restore stdout\n",
    "    \n",
    "    println(\"\\nObjective value: $(round(objective_value(m);digits=2))\")\n",
    "    println(\"x = $(value(x))\")\n",
    "    println(\"y = $(value(y))\")\n",
    "    \n",
    "    return x,y\n",
    "    \n",
    "end\n",
    "\n",
    "x,y = excercise_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#00B8DE\"> Exercise 3: constrained maximum likelihood estimation</span>\n",
    "\n",
    "> - Implement the maximum likelihood estimation of mean $\\mu$ and variance $\\sigma^2$ for Gaussian $\\mathcal{N}(0,1)$ sample\n",
    "> - Implement the same problem under additional constraint $\\mu=\\sigma^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without constraint\n",
      "\n",
      "Objective value: -1393.36\n",
      "μ = 0.010615355246404532\n",
      "σ = 0.9747453518972121\n",
      "\n",
      "With the constraint  μ = σ \n",
      "\n",
      "Objective value: -1882.5\n",
      "μ = 0.9695099250475486\n",
      "σ = 0.9695099250475486\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/JuliaOpt/JuMP.jl/blob/master/examples/mle.jl\n",
    "\n",
    "using JuMP, Ipopt, Random, Statistics, Test\n",
    "\n",
    "\"\"\"\n",
    "    example_mle()\n",
    "Use nonlinear optimization to compute the maximum likelihood estimate (MLE) of\n",
    "the parameters of a normal distribution aka the sample mean and variance\n",
    "\"\"\"\n",
    "\n",
    "function example_mle(N; verbose = true)\n",
    "                \n",
    "    x = randn(N)\n",
    "            \n",
    "    model = Model(with_optimizer(Ipopt.Optimizer))\n",
    "    @variable(model, μ>=0)\n",
    "    @variable(model, σ>=0)\n",
    "    @NLobjective(model, Max, N / 2 * log(1 / (2 * π * σ^2)) - sum((xi - μ)^2 for xi in x) / (2 * σ^2))\n",
    "\n",
    "    #print(model)\n",
    "    \n",
    "    std = stdout # save original stdout stream\n",
    "    redirect_stdout()\n",
    "    optimize!(model)\n",
    "    redirect_stdout(std) # restore stdout\n",
    "    \n",
    "    println(\"Without constraint\")\n",
    "    println(\"\\nObjective value: $(round(objective_value(model);digits=2))\")\n",
    "    println(\"μ = $(value(μ))\")\n",
    "    println(\"σ = $(value(σ))\")\n",
    "    println(\"\")\n",
    "    \n",
    "    #return μ,σ\n",
    "                \n",
    "    @NLconstraint(model, μ == σ)\n",
    "    optimize!(model)\n",
    "                \n",
    "    println(\"With the constraint  μ = σ \")\n",
    "    println(\"\\nObjective value: $(round(objective_value(model);digits=2))\")\n",
    "    println(\"μ = $(value(μ))\")\n",
    "    println(\"σ = $(value(σ))\")\n",
    "     \n",
    "end\n",
    "\n",
    "example_mle(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#00B8DE\"> Exercise 4: shape of a chain hang at both ends (catenary)</span>\n",
    "\n",
    "We want to compute the shape of a chain with endpoints $P_1=(0,1)$ and $P_2=(1,1.5)$. We assume the chain has $N\\_links = 10$ linear links, each with length $L\\_links = 2/N\\_links$. Compute the positions of the endpoints of the links and plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Objective value: 16.29\n",
      "x = [-0.0, 0.03, 0.07, 0.11, 0.16, 0.23, 0.3, 0.4, 0.5, 0.59, 0.66, 0.72, 0.77, 0.82, 0.85, 0.88, 0.91, 0.94, 0.96, 0.98, 1.0]\n",
      "y = [1.0, 0.91, 0.81, 0.72, 0.64, 0.56, 0.5, 0.46, 0.46, 0.5, 0.57, 0.65, 0.74, 0.83, 0.92, 1.01, 1.11, 1.21, 1.3, 1.4, 1.5]\n"
     ]
    }
   ],
   "source": [
    "using JuMP\n",
    "\n",
    "N_links = 20          # number of links\n",
    "N_ends  = N_links+1   # number of ends of links\n",
    "L_links = 2/N_links   # length of links\n",
    "\n",
    "\n",
    "model = Model(with_optimizer(Ipopt.Optimizer))\n",
    "\n",
    "@variable(model, x[1:N_ends])\n",
    "@variable(model, y[1:N_ends])\n",
    "@constraint(model, x[1] == 0)\n",
    "@constraint(model, x[N_ends] == 1)\n",
    "@constraint(model, y[1] == 1)\n",
    "@constraint(model, y[N_ends] == 1.5)\n",
    "#@constraint(model, diff(x).^2+diff(y).^2 .==L_links^2)\n",
    "for i in 1:N_links\n",
    "    @NLconstraint(model, (x[i+1]-x[i])^2+(y[i+1]-y[i])^2 == L_links^2)\n",
    "end\n",
    "\n",
    "@NLobjective(model, Min, sum(y[i] for i in 1:N_links))\n",
    "\n",
    "            \n",
    "#print(model)\n",
    "            \n",
    "optimize!(model)\n",
    "            \n",
    "sol_x = round.([JuMP.value(x[k]) for k=1:N_ends];digits=2)\n",
    "sol_y = round.([JuMP.value(y[k]) for k=1:N_ends];digits=2)\n",
    "\n",
    "\n",
    "println(\"\\nObjective value: $(round.(JuMP.objective_value(model);digits=2))\")\n",
    "println(\"x = $(round.([JuMP.value(x[k]) for k=1:N_ends];digits=2))\")\n",
    "println(\"y = $(round.([JuMP.value(y[k]) for k=1:N_ends];digits=2))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Plots\n",
    "pyplot()\n",
    "plot(sol_x, sol_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that by increasing N_ends, the solution gets softer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
